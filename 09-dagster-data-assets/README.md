# Dagster Data Assets Demo

A 10-minute demo showing how to set up Dagster for data asset management, pipeline orchestration, and data lineage tracking with modern data engineering practices.

## ğŸ—ï¸ Data Asset Management Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Raw Data    â”‚â”€â”€â”€â–¶â”‚ Data Assets â”‚â”€â”€â”€â–¶â”‚ Pipelines   â”‚â”€â”€â”€â–¶â”‚ Data Lineageâ”‚
â”‚ Sources     â”‚    â”‚ Management  â”‚    â”‚ Orchestrationâ”‚    â”‚ & Tracking  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚                    â”‚
                          â–¼                    â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ Asset       â”‚    â”‚  Dependency â”‚
                   â”‚ Dependenciesâ”‚    â”‚  Graphs     â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- pip
- Docker (optional)

### 1. Install Dagster
```bash
# Navigate to the demo
cd 09-dagster-data-assets

# Install Dagster
pip install dagster dagster-webserver dagster-postgres

# Install additional dependencies
pip install pandas numpy sqlalchemy psycopg2-binary
```

### 2. Start Dagster
```bash
# Start Dagster webserver
dagster dev

# Or use Docker Compose
docker-compose up -d
```

### 3. Run Sample Assets
```bash
# Run data assets pipeline
python assets/data_assets.py

# Run ETL assets pipeline
python assets/etl_assets.py

# Run analytics assets pipeline
python assets/analytics_assets.py
```

### 4. Access Dagster UI
- **Dagster UI**: `http://localhost:3000`
- **API**: `http://localhost:3000/graphql`

## ğŸ“ Project Structure

```
assets/
â”œâ”€â”€ data_assets.py        # Basic data assets
â”œâ”€â”€ etl_assets.py         # ETL asset pipeline
â”œâ”€â”€ analytics_assets.py   # Analytics asset pipeline
â””â”€â”€ utils/
    â”œâ”€â”€ data_processor.py # Data processing utilities
    â”œâ”€â”€ db_connector.py   # Database connection utilities
    â””â”€â”€ validators.py     # Data validation utilities

definitions/
â”œâ”€â”€ __init__.py           # Dagster definitions
â”œâ”€â”€ data_assets.py        # Data asset definitions
â”œâ”€â”€ etl_assets.py         # ETL asset definitions
â””â”€â”€ analytics_assets.py   # Analytics asset definitions

configs/
â”œâ”€â”€ dagster.yaml         # Dagster configuration
â””â”€â”€ assets/
    â”œâ”€â”€ data_assets.yaml     # Data asset configuration
    â”œâ”€â”€ etl_assets.yaml      # ETL asset configuration
    â””â”€â”€ analytics_assets.yaml # Analytics asset configuration

data/
â”œâ”€â”€ raw/                 # Raw data files
â”œâ”€â”€ processed/           # Processed data files
â”œâ”€â”€ analytics/           # Analytics outputs
â””â”€â”€ logs/               # Pipeline logs

scripts/
â”œâ”€â”€ setup_dagster.py     # Dagster setup script
â”œâ”€â”€ run_assets.py        # Asset runner script
â””â”€â”€ monitor_assets.py    # Asset monitoring script

notebooks/
â””â”€â”€ asset_analysis.ipynb # Jupyter notebook for analysis

docker-compose.yml        # Compose file for all services
README.md                 # This file
```

## ğŸ—ï¸ What This Demo Shows

1. **Dagster Setup**: Local deployment and configuration
2. **Data Assets**: Asset management and dependencies
3. **Pipeline Orchestration**: Asset-based pipeline execution
4. **Data Lineage**: Asset dependency tracking
5. **Monitoring**: Real-time asset monitoring and observability

## ğŸ¯ Key Concepts Demonstrated

- **Dagster**: Modern data orchestration platform
- **Data Assets**: Declarative data asset management
- **Asset Dependencies**: Automatic dependency resolution
- **Data Lineage**: End-to-end data flow tracking
- **Pipeline Orchestration**: Asset-based pipeline execution

## ğŸ”— Service Access

- **Dagster UI**: `http://localhost:3000`
- **GraphQL API**: `http://localhost:3000/graphql`
- **Asset Logs**: Local file system

## ğŸ“Š Sample Assets

- **Data Assets**: Raw data ingestion and validation
- **ETL Assets**: Data transformation and processing
- **Analytics Assets**: Business intelligence and reporting
- **Monitoring Assets**: Data quality and health checks

## ğŸš€ Next Steps

1. Add more complex asset dependencies
2. Set up external asset sources
3. Configure asset materialization
4. Add data quality checks
5. Integrate with external systems

## ğŸ› Troubleshooting

**Dagster Issues**: Check server status
```bash
dagster dev --package-name assets
```

**Asset Issues**: Check asset logs
```bash
dagster asset materialize --select data_assets
```

**Connection Issues**: Verify configuration
```bash
dagster config validate
``` 